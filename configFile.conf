arch = ${features},${classifier}
features = ${c0},${s1},${c2},${s3}
classifier = ${c5},${f7}
nonlin          = tanh  # type of non-linearity                                                                                                                                      
pool            = l2pool  # subs (is another option) 
# main branch layers                                                                                                                                                                 
c0              = conv0,addc0,${nonlin},abs0,wstd0
s1              = ${pool}1,addc1,${nonlin}
c2              = conv2,addc2,${nonlin},abs2,wstd2
s3              = ${pool}3,addc3,${nonlin}
c5              = conv5,addc5,${nonlin}
f7              = linear7,addc7,${nonlin}

# main branch parameters
classifier_hidden = 16  # number of hidden units in 2-layer classifier

conv0_kernel    = 5x5 # convolution kernel sizes (hxw)
conv0_stride    = 1x1 # convolution strides  (hxw)
conv0_table     =     # convolution table (optional)
conv0_table_in  = 1   # conv input max, used if table file not defined
conv0_table_out = 6   # features max, used if table file not defined
conv0_weights   =     # manual loading of weights (optional)
addc0_weights   =     # manual loading of weights (optional)
wstd0_kernel    = ${conv0_kernel} # normalization kernel sizes (hxw)
subs1_kernel    = 2x2 # subsampling kernel sizes (hxw)
subs1_stride    = ${subs1_kernel} # subsampling strides (hxw)
l2pool1_kernel  = 2x2 # subsampling kernel sizes (hxw)
l2pool1_stride  = ${l2pool1_kernel} # subsampling strides (hxw)
addc1_weights   =  # manual loading of weights (optional)
conv2_kernel    = 5x5 # convolution kernel sizes (hxw)
conv2_stride    = 1x1 # convolution strides (hxw)
#conv2_table     = ${tblroot}/table_6_16_connect_60.mat # conv table (optional)
conv2_table_in  = thickness # use current thickness as max table input
conv2_table_out = 16 # features max, used if table file not defined
conv2_weights   =     # manual loading of weights (optional)
addc2_weights   =     # manual loading of weights (optional)
wstd2_kernel    = ${conv2_kernel} # normalization kernel sizes (hxw)
subs3_kernel    = 2x2 # subsampling kernel sizes (hxw)
subs3_stride    = ${subs3_kernel} # subsampling strides (hxw)
l2pool3_kernel  = 2x2 # l2poolampling kernel sizes (hxw)
l2pool3_stride  = ${l2pool3_kernel} # subsampling strides (hxw)
addc3_weights   =     # manual loading of weights (optional)
linear5_in      = ${linear5_in_${net}} # linear module input features size
linear5_out     = noutputs # use number of classes as max table output
linear6_in      = thickness # linear module input features size
linear6_out     = ${classifier_hidden}
linear7_in      = thickness # use current thickness
linear7_out     = noutputs # use number of classes as max table output
conv5_kernel    = 5x5 # convolution kernel sizes (hxw)
conv5_stride    = 1x1 # convolution strides (hxw)
conv5_table_in  = thickness # use current thickness as max table input
conv5_table_out = 120 # features max, used if table file not defined

# training #####################################################################
classification  = 1 # load datasets in classification mode, regression otherwise
dataset_path    = C:\Users\Anand Karra\Desktop\Test project #replace this with where your dataset files are
train           = ${dataset_path}\standard_train\test_train_data.mat # training data
train_labels    = ${dataset_path}\standard_train\test_train_labels.mat # training labels
train_size      = 853                          # limit number of samples
val             = ${dataset_path}\standard_validate\test_val_data.mat  # validation data
val_labels      = ${dataset_path}\standard_validate\test_val_labels.mat  # validation labels          
val_size        = 600                        # limit number of samples

# energies & answers ###########################################################
trainer         = trainable_module1  # the trainer module
trainable_module1_energy = l2_energy # type of energy
answer          = class_answer # how to infer answers from network raw outputs
# hyper-parameters
eta             = .0001  # learning rate
reg             = 0      # regularization
reg_l1          = ${reg} # L1 regularization
reg_l2          = ${reg} # L2 regularization
reg_time        = 0      # time (in samples) after which to start regularizing
inertia         = 0.0    # gradient inertia
anneal_value    = 0.0    # learning rate decay value
anneal_period   = 0      # period (in samples) at which to decay learning rate
gradient_threshold = 0.9		
iterations      = 2     # number of training iterations
ndiaghessian    = 100    # number of sample for 2nd derivatives estimation
epoch_mode      = 1      # 0: fixed number 1: show all at least once
#epoch_size = 4000    # number of training samples per epoch. comment to ignore.
epoch_show_modulo = 400  # print message every n training samples
sample_probabilities = 0 # use probabilities to pick samples
hardest_focus   = 1      # 0: focus on easiest samples 1: focus on hardest ones
ignore_correct  = 0      # If 1, do not train on correctly classified samples
min_sample_weight = 0    # minimum probability of each sample
per_class_norm  = 1      # normalize probabiliy by class (1) or globally (0)
shuffle_passes  = 1      # shuffle samples between passes
balanced_training = 1    # show each class the same amount of samples or not
random_class_order = 0   # class order is randomized or not when balanced
no_training_test = 0     # do not test on training set if 1
no_testing_test = 0      # do not test on testing set if 1
max_testing     = 0      # limit testing to this number of samples
save_pickings   = 0      # save sample picking statistics
binary_target   = 0      # use only 1 output, -1 is negative, +1 positive
test_only       = 0      # if 1, just test the data and return
save_weights    = 0      # if 0, do not save weights after each iteration
keep_outputs    = 1      # keep all outputs in memory
training_precision = double #float
save_weights    = 1      # if 0, do not save weights when training

# training display #############################################################
display               = 1  # display results
show_conf             = 0  # show configuration variables or not
show_train            = 1  # enable/disable all training display
show_train_ninternals = 1  # number of internal examples to display
show_train_errors     = 0  # show worst errors on training set
show_train_correct    = 0  # show worst corrects on training set
show_val_errors       = 0  # show worst errors on validation set
show_val_correct      = 1  # show worst corrects on validation set
show_hsample          = 5  # number of samples to show on height axis
show_wsample          = 18 # number of samples to show on height axis
show_wait_user        = 0  # if 1, wait for user to close windows
